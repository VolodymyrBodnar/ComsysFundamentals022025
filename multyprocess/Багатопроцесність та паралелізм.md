
### **Частина 1: Теорія паралельних обчислень**

#### **1. Вступ до багатопроцесності**

Багатопроцесність – це підхід до програмування, що дозволяє використовувати кілька незалежних процесів для виконання обчислень паралельно. Основна ідея полягає в тому, що кожен процес має власну пам’ять і ресурси, що дозволяє уникати обмежень, які накладає багатопотоковість. Завдяки цьому можна повною мірою використовувати багатоядерні процесори, розподіляючи навантаження між кількома ядрами.

На відміну від багатопотоковості, де всі потоки ділять один простір пам’яті, кожен процес виконується ізольовано. Це зменшує ризик взаємного блокування або неочікуваних змін даних, але додає складності у спільному використанні ресурсів. Саме тому міжпроцесорна взаємодія (IPC) є важливою темою, яка потребує окремого розгляду.

Багатопроцесність особливо ефективна для задач, що активно використовують центральний процесор. Наприклад, складні математичні обчислення, обробка великих масивів даних або рендеринг зображень можуть значно прискоритися при правильному використанні цього підходу. Водночас, запуск нових процесів має певні витрати, тому важливо розуміти, коли цей підхід дасть відчутний приріст продуктивності, а коли він може лише ускладнити програму.

### **2. Архітектурні аспекти паралельних обчислень**

Паралельні обчислення тісно пов’язані з апаратною архітектурою комп’ютера. Сучасні процесори можуть мати кілька ядер, кожне з яких здатне виконувати інструкції незалежно від інших. Це означає, що, розподіляючи обчислення між різними процесами, можна значно прискорити виконання задач.

Існують різні моделі паралельних обчислень, але найважливішими для програміста є дві: **SIMD (Single Instruction, Multiple Data)** і **MIMD (Multiple Instruction, Multiple Data)**. Перша використовується у випадках, коли одна й та сама операція виконується над великим обсягом даних, наприклад у графічних обчисленнях або при роботі з векторними процесорами. Друга модель дозволяє кожному ядру виконувати власні незалежні інструкції, що характерно для багатопроцесної обробки.

Контекстне перемикання між процесами — одна з причин, чому паралельні обчислення не завжди дають очікуваний приріст продуктивності. Кожного разу, коли процесор переключається між процесами, операційна система повинна зберегти поточний стан одного процесу та завантажити стан іншого. Це додає накладні витрати, особливо якщо процеси часто взаємодіють між собою.

Ще один важливий аспект — використання кешу процесора. Якщо кілька процесів працюють з одними й тими ж даними, їх можна зберігати в кеші, що значно прискорює обчислення. Проте, якщо процеси звертаються до різних областей пам’яті, це може спричиняти часті «промахи кешу» і уповільнювати роботу. Це пояснює, чому іноді вигідніше мати менше процесів, які ефективніше використовують кеш, ніж багато процесів, що конкурують за доступ до пам’яті.

Паралельні обчислення також залежать від моделі пам’яті. У багатьох сучасних системах кожне ядро має власний кеш, але всі вони використовують спільну оперативну пам’ять. Це означає, що при неправильному плануванні процеси можуть блокувати один одного при спробі запису в спільну область пам’яті. Для уникнення таких проблем існують механізми синхронізації, які дозволяють процесам координувати свої дії, але їх використання також має певні витрати.

Таким чином, ефективне використання багатопроцесності вимагає розуміння особливостей апаратної архітектури, принципів управління пам’яттю та алгоритмів розподілу навантаження між процесами.

### **3. Які задачі ефективно паралелізуються, а які ні?**

Не всі алгоритми та обчислювальні задачі однаково добре піддаються розпаралелюванню. Основний принцип, за яким визначають доцільність використання багатопроцесності, – це рівень залежності між частинами обчислень. Чим менше залежностей між окремими обчислювальними операціями, тим легше їх розподілити між процесами без втрати продуктивності.

Задачі, які добре піддаються паралелізації, зазвичай мають незалежні частини, які можна виконувати одночасно. Наприклад, обчислення значень функцій на незалежних наборах даних, обробка великих масивів чисел, рендеринг зображень та відео, симуляції фізичних процесів або глибоке навчання. У цих випадках кожен процес може отримати свою порцію даних і виконувати розрахунки без необхідності частої комунікації з іншими процесами.

Алгоритми сортування, такі як **QuickSort** або **MergeSort**, також можуть бути ефективно розпаралелені. У QuickSort рекурсивний поділ масиву можна розподілити між процесами, а в MergeSort злиття підмасивів може виконуватися незалежно на різних рівнях рекурсії.

Методи чисельного інтегрування та симуляції, наприклад **метод Монте-Карло**, також є чудовими кандидатами для багатопроцесної обробки. Оскільки кожен експеримент у такому методі не залежить від попередніх, процеси можуть працювати незалежно, а потім результати просто підсумовуються.

Однак існують задачі, які складно або навіть неможливо ефективно розпаралелити. Алгоритми, де кожен наступний етап залежить від результатів попереднього, не отримають значного прискорення. Наприклад, рекурсивні обчислення **послідовності Фібоначчі** зазвичай неефективно розпаралелити через залежності між кожним наступним значенням.

Задачі, що активно взаємодіють зі спільною пам’яттю, також можуть бути складними для паралелізації. Наприклад, операції з великими структурами даних, що потребують частого доступу до пам’яті та блокування ресурсів, можуть втрачати продуктивність через необхідність синхронізації.

Варто також враховувати, що запуск процесів сам по собі має накладні витрати. Якщо завдання займає мало часу або якщо кожен процес потребує частого обміну даними, вигода від багатопроцесності може бути нівельована. Тому перед тим як розпаралелювати алгоритм, варто оцінити, чи дасть це реальний приріст продуктивності.

### **4. Як визначити, чи варто використовувати багатопроцесність?**

Перед тим як реалізовувати багатопроцесність у своєму коді, важливо зрозуміти, чи дійсно це дасть відчутний приріст продуктивності. Запуск додаткових процесів не завжди означає пришвидшення роботи, оскільки сам факт створення та синхронізації процесів має накладні витрати.

Перший крок – **визначити тип задачі**. Якщо основне навантаження у вашій програмі припадає на обчислення, то, ймовірно, багатопроцесність допоможе. Це стосується задач, які потребують інтенсивного використання процесора, наприклад обчислення великих матриць, симуляції фізичних процесів або аналізу великих масивів чисел. Натомість, якщо програма витрачає багато часу на очікування відповіді від зовнішніх джерел (наприклад, робота з мережею, базами даних, файловою системою), використання багатопотоковості або асинхронного підходу може бути більш ефективним.

Другий крок – **виміряти продуктивність** вашого коду за допомогою профілювання. У Python для цього можна використовувати модулі `timeit`, `perf_counter` або `cProfile`. Наприклад, якщо ви хочете дізнатися, скільки часу займає виконання певної функції, можна використати наступний підхід:

```python
import time
from multiprocessing import Pool

def heavy_computation(x):
    return sum(i**2 for i in range(x))

if __name__ == "__main__":
    x = 10**6
    start = time.perf_counter()
    heavy_computation(x)  # Виконання у звичайному режимі
    end = time.perf_counter()
    print(f"Час виконання без паралелізації: {end - start:.5f} сек")

    start = time.perf_counter()
    with Pool(4) as pool:
        pool.map(heavy_computation, [x//4] * 4)  # Розподіл обчислень на 4 процеси
    end = time.perf_counter()
    print(f"Час виконання з багатопроцесністю: {end - start:.5f} сек")
```

Якщо після запуску цього коду ви бачите значне прискорення у виконанні багатопроцесного варіанта, то ваш алгоритм добре масштабується. Якщо ж різниця мінімальна або навіть негативна, то можливо, накладні витрати на створення процесів переважають над вигодами від паралелізації.

Ще один важливий критерій – **Закон Амдала**, який говорить, що приріст продуктивності від розпаралелювання обмежений тією частиною коду, яка може виконуватися незалежно. Якщо значна частина вашої програми все одно виконується послідовно, то навіть розподіл роботи між великою кількістю процесів не дасть бажаного ефекту.

Також варто звернути увагу на **ресурси системи**. Якщо у вас 4-ядерний процесор, то використання 8 або більше процесів не дасть значного виграшу в продуктивності, а може навіть знизити її через накладні витрати на перемикання контексту. У таких випадках корисно перевірити, скільки ядер доступно, використовуючи `os.cpu_count()`, і підбирати кількість процесів відповідно до цього значення.

Оцінка продуктивності – це ключовий момент при розробці ефективних багатопроцесних алгоритмів. Важливо розуміти, чи буде приріст виправданим, оскільки іноді простіше і продуктивніше оптимізувати алгоритм, ніж намагатися розпаралелити його виконання.
### **5. Створення та управління процесами**

У Python створення та управління процесами виконується за допомогою модуля `multiprocessing`. Основним класом є `multiprocessing.Process`, який дозволяє створювати незалежні процеси, кожен з яких працює у власному середовищі та не ділить пам’ять з іншими процесами.

Щоб запустити новий процес, достатньо створити об’єкт `Process`, передати йому цільову функцію (`target`) та аргументи (`args`), а потім викликати метод `start()`. Ось найпростіший приклад створення та запуску окремого процесу:

```python
from multiprocessing import Process

def worker():
    print("Процес працює!")

if __name__ == "__main__":
    p = Process(target=worker)
    p.start()
    p.join()
```

Метод `start()` запускає процес, який починає виконувати вказану функцію. Важливо викликати `join()`, щоб головний процес дочекався завершення дочірнього процесу, інакше програма може завершитися раніше, ніж встигне виконатися код у створеному процесі.

При створенні кількох процесів їх можна запускати у циклі. Наприклад, якщо потрібно запустити кілька однакових обчислень паралельно:

```python
def worker(name):
    print(f"Процес {name} запущено")

if __name__ == "__main__":
    processes = []
    for i in range(4):
        p = Process(target=worker, args=(f"P{i+1}",))
        p.start()
        processes.append(p)

    for p in processes:
        p.join()
```

Кожен процес отримує унікальну назву, а головний процес чекає завершення всіх створених процесів.

Однією з важливих особливостей роботи з `multiprocessing` є те, що код повинен бути розміщений у блоці `if __name__ == "__main__"`. Це потрібно, щоб уникнути рекурсивного створення процесів, яке може статися в Windows через механізм `spawn`, коли новий процес копіює головний процес та повторно виконує його код.

Якщо потрібно **примусово завершити процес**, можна використати `terminate()`, але слід бути обережним, оскільки процес завершиться негайно, без можливості коректного збереження даних або очищення ресурсів.

```python
from time import sleep

def long_task():
    while True:
        print("Процес працює...")
        sleep(1)

if __name__ == "__main__":
    p = Process(target=long_task)
    p.start()
    sleep(3)
    p.terminate()
    print("Процес завершено примусово")
```

Використання `terminate()` може знадобитися у випадках, коли процес завис або виконується надто довго. Однак, якщо є можливість, краще використовувати механізми перевірки стану або передачі сигналів для коректного завершення роботи процесів.

Коли потрібно створити велику кількість процесів або контролювати їхнє виконання, варто звернути увагу на `multiprocessing.Pool`, який спрощує розподіл задач між процесами, що буде розглянуто пізніше.

### **6. Обмін даними між процесами (IPC)**

Оскільки кожен процес у Python має власний простір пам’яті, вони не можуть напряму отримувати доступ до змінних інших процесів. Для організації взаємодії між процесами використовують механізми міжпроцесної комунікації (IPC – Inter-Process Communication). Python пропонує кілька способів передачі даних між процесами: **черги (Queue), канали (Pipe) та менеджери (Manager)**.

#### **Використання черги (Queue)**

Черга (`multiprocessing.Queue`) дозволяє передавати дані між процесами у стилі "першим прийшов – першим оброблено" (FIFO). Вона працює аналогічно `queue.Queue` у багатопотоковості, але адаптована для міжпроцесного зв’язку.

Ось приклад, де один процес відправляє повідомлення в чергу, а інший отримує його:

```python
from multiprocessing import Process, Queue

def sender(q):
    q.put("Привіт від процесу!")

def receiver(q):
    message = q.get()
    print(f"Отримано повідомлення: {message}")

if __name__ == "__main__":
    q = Queue()
    p1 = Process(target=sender, args=(q,))
    p2 = Process(target=receiver, args=(q,))

    p1.start()
    p2.start()

    p1.join()
    p2.join()
```

Процес `sender` відправляє рядок у чергу, а процес `receiver` отримує його та виводить у консоль. Черги є простим і зручним способом передавати дані між процесами, особливо коли потрібно уникати конфліктів доступу до пам’яті.

#### **Використання каналів (Pipe)**

Канали (`multiprocessing.Pipe`) дозволяють процесам взаємодіяти напряму. `Pipe()` створює двосторонній канал із двома кінцями (`parent_conn` і `child_conn`), через які можна передавати дані.

```python
from multiprocessing import Process, Pipe

def worker(conn):
    conn.send("Дані від дочірнього процесу")
    conn.close()

if __name__ == "__main__":
    parent_conn, child_conn = Pipe()
    p = Process(target=worker, args=(child_conn,))
    p.start()
    print(f"Отримано: {parent_conn.recv()}")
    p.join()
```

У цьому прикладі дочірній процес надсилає повідомлення через `Pipe`, а батьківський процес отримує його. На відміну від `Queue`, канал працює лише між двома процесами і може використовуватися для більш контрольованого обміну даними.

#### **Використання менеджера (Manager) для спільних структур**

Якщо потрібно передавати між процесами складні структури, такі як списки або словники, можна скористатися `multiprocessing.Manager`. Менеджер дозволяє створювати об’єкти, які доступні для кількох процесів і синхронізують доступ до своїх даних.

```python
from multiprocessing import Manager, Process

def worker(d, l):
    d["x"] += 1
    l.append("Новий елемент")

if __name__ == "__main__":
    with Manager() as manager:
        shared_dict = manager.dict({"x": 5})
        shared_list = manager.list(["Елемент 1"])

        p = Process(target=worker, args=(shared_dict, shared_list))
        p.start()
        p.join()

        print(shared_dict)  # {"x": 6}
        print(shared_list)  # ["Елемент 1", "Новий елемент"]
```

Менеджери зручні, коли потрібно працювати зі структурами даних у різних процесах, але вони мають певні накладні витрати, оскільки всі зміни проходять через проксі-об’єкти.

### **Що вибрати?**

- **Queue** – якщо потрібно передавати повідомлення між процесами, особливо у стилі продюсер-споживач.
- **Pipe** – якщо потрібно швидко передати дані між двома процесами.
- **Manager** – якщо потрібно працювати зі складними структурами даних, доступними для кількох процесів.

Ці механізми дозволяють ефективно організовувати взаємодію між процесами та уникати проблем із розподілом пам’яті.


### **8. Пул процесів та ефективний розподіл задач**

Коли потрібно виконати велику кількість незалежних обчислень у різних процесах, створювати кожен процес вручну може бути неефективно. Запуск і завершення процесів потребують ресурсів, а їхня кількість обмежена можливостями процесора. Щоб спростити управління великою кількістю процесів, Python надає механізм **пулу процесів (`multiprocessing.Pool`)**, який автоматично розподіляє завдання між певною кількістю процесів.

Пул процесів дозволяє створити обмежену кількість процесів, які повторно використовуються для виконання задач. Це особливо корисно, коли потрібно обробити великий набір даних або виконати однакову операцію над великою кількістю елементів.

#### **Створення пулу процесів та використання `map`**

Найпростіший спосіб розподілити завдання між процесами – використовувати `Pool.map()`. Він працює аналогічно звичайному `map()` у Python, але виконує функцію в кількох процесах одночасно.

```python
from multiprocessing import Pool

def square(n):
    return n * n

if __name__ == "__main__":
    numbers = [1, 2, 3, 4, 5, 6, 7, 8]
    
    with Pool(4) as pool:  # Використовуємо 4 процеси
        results = pool.map(square, numbers)
    
    print(results)  # [1, 4, 9, 16, 25, 36, 49, 64]
```

У цьому коді список чисел ділиться між 4 процесами, кожен з яких обчислює квадрат частини чисел. Це дозволяє ефективно використовувати ресурси процесора без потреби створювати процеси вручну.

#### **Різниця між `map`, `apply` та `apply_async`**

Метод `map()` очікує завершення всіх завдань і повертає результати у вигляді списку. Якщо потрібно обробляти кожне завдання окремо, можна використовувати `apply()` або `apply_async()`.

```python
from multiprocessing import Pool
import time

def worker(x):
    time.sleep(1)
    return x * x

if __name__ == "__main__":
    with Pool(4) as pool:
        result = pool.apply(worker, (5,))  # Виконується лише одне завдання
        print(result)  # 25
```

Метод `apply()` виконує одну задачу у пулі, а потім повертає результат. Однак він **блокує виконання** наступних операцій, доки не отримає результат.

Якщо потрібно виконати завдання асинхронно, можна використати `apply_async()`, який повертає об’єкт `AsyncResult`, що дозволяє отримати результат пізніше.

```python
from multiprocessing import Pool

def worker(x):
    return x * x

if __name__ == "__main__":
    with Pool(4) as pool:
        result = pool.apply_async(worker, (5,))
        print(result.get())  # Отримуємо результат, коли процес завершиться
```

Асинхронний підхід корисний, коли не потрібно чекати завершення кожного завдання перед запуском наступного.

#### **Розподіл задач із `starmap` для функцій із кількома аргументами**

Якщо функція приймає кілька аргументів, замість `map()` можна використовувати `starmap()`, яка передає кожен набір аргументів окремо.

```python
from multiprocessing import Pool

def multiply(a, b):
    return a * b

if __name__ == "__main__":
    data = [(1, 2), (3, 4), (5, 6)]
    
    with Pool(3) as pool:
        results = pool.starmap(multiply, data)
    
    print(results)  # [2, 12, 30]
```

Тут кожна пара чисел передається у функцію `multiply`, що дозволяє виконати обчислення паралельно.

#### **Порівняння з `concurrent.futures.ProcessPoolExecutor`**

Python також має модуль `concurrent.futures`, який надає клас `ProcessPoolExecutor` для роботи з процесами. Він має схожий функціонал із `multiprocessing.Pool`, але надає більш зручний інтерфейс.

```python
from concurrent.futures import ProcessPoolExecutor

def square(n):
    return n * n

if __name__ == "__main__":
    numbers = [1, 2, 3, 4, 5, 6, 7, 8]
    
    with ProcessPoolExecutor(max_workers=4) as executor:
        results = list(executor.map(square, numbers))

    print(results)  # [1, 4, 9, 16, 25, 36, 49, 64]
```

Основна різниця між `Pool` і `ProcessPoolExecutor`:

- `multiprocessing.Pool` – надає гнучкі методи (`map`, `apply`, `starmap`), але вимагає використання контекстного менеджера або явного закриття `pool.close()`.
- `ProcessPoolExecutor` – має простіший API та автоматично керує завершенням процесів.


### **9. Приклад: використання `Pool.map` для обчислень**

Щоб на практиці зрозуміти, як `Pool.map()` допомагає прискорювати обчислення, розглянемо реальний приклад, у якому необхідно паралельно обробити великий набір даних.

Припустимо, що у нас є функція, яка імітує складні обчислення, наприклад, обчислює факторіал великого числа. Якщо виконувати ці обчислення послідовно, то час виконання буде значним. Використання `Pool.map()` дозволить розділити роботу між кількома процесами та прискорити обчислення.

```python
from multiprocessing import Pool
import time
import math

def compute_factorial(n):
    return math.factorial(n)

if __name__ == "__main__":
    numbers = [50000, 60000, 70000, 80000]  # Вхідні дані
    start = time.perf_counter()

    with Pool(4) as pool:  # Запускаємо пул із 4 процесів
        results = pool.map(compute_factorial, numbers)

    end = time.perf_counter()
    print(f"Час виконання: {end - start:.5f} сек")
```

У цьому прикладі список чисел ділиться між чотирма процесами, кожен з яких обчислює факторіал окремого числа. Завдяки цьому загальний час обчислень скорочується, оскільки процесорні ресурси використовуються ефективніше.

### **Чому `Pool.map()` є ефективним?**

1. **Автоматичний розподіл завдань**. `Pool.map()` бере на себе розподіл роботи між процесами, тому не потрібно вручну керувати чергою задач.
2. **Повторне використання процесів**. `Pool` створює обмежену кількість процесів, які повторно використовуються для виконання завдань, що значно зменшує накладні витрати.
3. **Простота коду**. Використання `map()` дозволяє записати код у функціональному стилі без необхідності вручну запускати та завершувати процеси.

### **Порівняння з послідовним виконанням**

Щоб оцінити вигоду від багатопроцесності, спробуємо виконати ці самі обчислення без `multiprocessing`:

```python
start = time.perf_counter()
results = [compute_factorial(n) for n in numbers]
end = time.perf_counter()
print(f"Час виконання без багатопроцесності: {end - start:.5f} сек")
```

У цьому випадку всі обчислення виконуються послідовно, і якщо порівняти час виконання з `Pool.map()`, то можна побачити значний приріст швидкості.

### **Коли `Pool.map()` неефективний?**

- Якщо завдання займає дуже мало часу, накладні витрати на створення процесів можуть переважити вигоду від паралелізації.
- Якщо процеси часто потребують обміну великими обсягами даних, комунікація між ними може стати вузьким місцем.
- Якщо ресурсів процесора недостатньо (наприклад, використовується більше процесів, ніж доступно ядер), ефективність може знизитися через перемикання контексту.

Таким чином, використання `Pool.map()` виправдане, коли потрібно розпаралелити обчислення, що займають значний час, але слід пам’ятати про накладні витрати, пов’язані зі створенням та комунікацією процесів.
### **Метод Монте-Карло

Метод Монте-Карло – це чисельний підхід до розв’язання задач, що ґрунтується на використанні випадкових вибірок та статистичних оцінок. Він широко застосовується в математичному моделюванні, фізиці, фінансах, машинному навчанні та інших галузях, де аналітичні або точні методи є надто складними або неможливими для реалізації.

Основна ідея методу полягає у тому, щоб багаторазово виконати випадкові випробування (симуляції) та на основі їх результатів оцінити шукану величину. Наприклад, якщо потрібно знайти площу фігури, можна випадково розкидати точки у відомій області (наприклад, квадраті) та підрахувати, яка частка з них потрапляє всередину цієї фігури. Якщо взяти достатньо велику кількість точок, отримана оцінка буде наближатися до точного значення.

Метод Монте-Карло добре піддається паралелізації, оскільки кожне випробування є незалежним від інших. Це означає, що можна розбити загальну кількість випробувань між процесами, кожен з яких буде виконувати свою частину роботи, а потім підсумувати результати.

Наприклад, можна використати цей метод для наближеного обчислення числа **π**. Якщо уявити коло радіусом 1, вписане у квадрат 2×2, то відношення площі кола до площі квадрата дорівнює π/4. Якщо випадковим чином розкидати точки у квадраті, то частка тих, які потрапили в коло, дозволить оцінити значення π.

Ось як можна реалізувати цей підхід у Python за допомогою `multiprocessing`:

```python
import random
from multiprocessing import Pool

def monte_carlo_pi(n_samples):
    count = 0
    for _ in range(n_samples):
        x, y = random.uniform(-1, 1), random.uniform(-1, 1)
        if x**2 + y**2 <= 1:
            count += 1
    return count

if __name__ == "__main__":
    n_samples = 10**6  # Загальна кількість точок
    n_processes = 4     # Кількість процесів

    with Pool(n_processes) as pool:
        results = pool.map(monte_carlo_pi, [n_samples // n_processes] * n_processes)

    pi_estimate = (4 * sum(results)) / n_samples
    print(f"Оцінка числа π: {pi_estimate}")
```

У цьому прикладі всі процеси незалежно виконують однакову кількість випробувань, а потім результати просто підсумовуються. Завдяки цьому ми отримуємо майже ідеальний приріст продуктивності при збільшенні кількості процесів, оскільки кожен працює зі своїм набором даних без потреби в синхронізації чи обміні інформацією між процесами під час виконання.

Метод Монте-Карло є класичним прикладом задачі, що чудово масштабується при використанні багатопроцесності, оскільки обчислення є повністю незалежними і майже не вимагають комунікації між процесами.

### **Паралельна реалізація алгоритму KNN за допомогою `multiprocessing`**

#### **Опис реалізації**

K-Nearest Neighbors (KNN) – це алгоритм класифікації, який визначає клас тестового зразка на основі найближчих сусідів у навчальному наборі даних. Основний обчислювальний процес у KNN – це обчислення відстаней від тестового зразка до всіх точок у навчальному наборі, що добре піддається паралелізації.

У цьому коді:

1. **Послідовна версія** – кожен тестовий зразок обробляється по черзі.
2. **Паралельна версія** – використовує `multiprocessing.Pool` для обробки кожного тестового зразка в окремому процесі.
3. **Оцінюється продуктивність** обох підходів шляхом вимірювання часу виконання.

---

### **Код KNN із паралельним виконанням**

```python
import numpy as np
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from multiprocessing import Pool
import time

# Завантаження датасету ірисів
iris = load_iris()
X, y = iris.data, iris.target

# Розділяємо дані на тренувальні та тестові
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Функція обчислення евклідової відстані
def euclidean_distance(a, b):
    return np.sqrt(np.sum((a - b) ** 2))

# Функція для передбачення класу одного тестового зразка
def knn_predict(test_sample):
    k = 5  # Кількість найближчих сусідів
    distances = [euclidean_distance(test_sample, train_sample) for train_sample in X_train]
    nearest_indices = np.argsort(distances)[:k]  # Знаходимо k найближчих сусідів
    nearest_labels = y_train[nearest_indices]  # Беремо їхні мітки
    prediction = np.bincount(nearest_labels).argmax()  # Визначаємо найчастіший клас
    return prediction

# --- Послідовне виконання ---
start_seq = time.perf_counter()
predictions_seq = [knn_predict(sample) for sample in X_test]
end_seq = time.perf_counter()
time_seq = end_seq - start_seq

# --- Паралельне виконання з multiprocessing ---
start_par = time.perf_counter()
with Pool() as pool:
    predictions_par = pool.map(knn_predict, X_test)
end_par = time.perf_counter()
time_par = end_par - start_par

# Оцінка точності
accuracy_seq = np.mean(np.array(predictions_seq) == y_test)
accuracy_par = np.mean(np.array(predictions_par) == y_test)

# Вивід результатів
print(f"Точність (послідовно): {accuracy_seq:.5f}")
print(f"Час виконання (послідовно): {time_seq:.5f} с")
print(f"Точність (паралельно): {accuracy_par:.5f}")
print(f"Час виконання (паралельно): {time_par:.5f} с")
```

---

### **Пояснення коду**

1. **Дані**
    
    - Використовується стандартний набір ірисів (`sklearn.datasets.load_iris`).
    - Розділяємо дані на навчальні (`X_train, y_train`) та тестові (`X_test, y_test`).
2. **Функція `knn_predict()`**
    
    - Обчислює відстані між тестовим зразком та всіма точками тренувального набору.
    - Знаходить **k** найближчих сусідів (`k=5`).
    - Визначає найбільш популярний клас серед сусідів.
3. **Послідовне виконання**
    
    - Виконуємо передбачення для кожного тестового зразка у циклі.
    - Вимірюємо час виконання.
4. **Паралельне виконання (`Pool.map()`)**
    
    - Використовуємо пул процесів (`multiprocessing.Pool`).
    - Кожен тестовий зразок передається в окремий процес для передбачення.
    - Збираємо результати.
5. **Оцінка продуктивності**
    
    - Виводимо точність класифікації та час виконання обох методів.

---

### **Очікувані результати**

- Точність послідовної та паралельної версій повинна бути **однаковою**, оскільки алгоритм не змінюється.
- Час виконання **паралельної версії має бути меншим**, особливо на багатоядерних процесорах.
- Виграш у швидкості **залежить від кількості ядер** і розміру тестового набору. На малих обсягах даних вигода може бути незначною через накладні витрати на створення процесів.

---

### **Коли цей підхід ефективний?**

- Велика кількість тестових зразків (`X_test` має бути достатньо великим).
- Потужний процесор із багатьма ядрами.
- Відносно складні обчислення, які можуть добре масштабується між процесами.

Якщо набір даних маленький, то накладні витрати на створення процесів можуть зменшити вигоду від паралельного виконання.