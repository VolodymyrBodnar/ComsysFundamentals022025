
### **IO-bound та CPU-bound задачі**

У багатопотоковості дуже важливо розуміти, для яких задач вона буде корисною, а для яких – навпаки, створюватиме проблеми. Всі задачі можна умовно розділити на дві категорії: ті, що залежать від швидкості обміну даними із зовнішніми системами (IO-bound), та ті, що потребують великих обчислювальних ресурсів (CPU-bound).

Задачі, які є IO-bound, це такі, де основний час витрачається на очікування відповіді від зовнішнього джерела. Це може бути запит до бази даних, читання або запис файлу на диск, скачування веб-сторінки або відправлення HTTP-запиту. У таких випадках процесор виконує мінімальну кількість роботи, а більшу частину часу простоює, очікуючи відповідь. Тут багатопоточність дійсно корисна, тому що навіть за наявності GIL один потік може передати управління іншому в той момент, коли сам простоює. Таким чином, програма може одночасно відправляти кілька запитів і отримувати відповіді набагато швидше, ніж якби всі запити виконувалися послідовно в одному потоці.

Для прикладу можна розглянути задачу, в якій потрібно завантажити десять веб-сторінок. Якщо робити це послідовно, кожен запит буде чекати відповіді перед тим, як відправити наступний. Натомість, використовуючи багатопоточність, можна запустити всі запити одночасно, і програма зможе працювати значно швидше. Ось код, який демонструє таку поведінку:

```python
import threading
import requests

urls = ["https://example.com" for _ in range(10)]

def fetch(url):
    resp = requests.get(url)
    print(f"Завантажено: {url}")

threads = [threading.Thread(target=fetch, args=(url,)) for url in urls]
for t in threads: t.start()
for t in threads: t.join()
```

Тут кожен потік буде займатися завантаженням окремого сайту, і загальний час виконання скоротиться, адже потоки працюватимуть одночасно, поки чекають відповіді від сервера.

На противагу цьому, CPU-bound задачі мають зовсім іншу природу. Це такі задачі, де головне навантаження припадає саме на процесор. Це можуть бути складні математичні обчислення, кодування відео, обробка великих масивів даних або моделювання фізичних процесів. У такому випадку головним обмеженням є можливості процесора, а не швидкість обміну даними з іншими системами.

Коли виконуються CPU-bound задачі, потоки не просто очікують на зовнішні ресурси, а активно використовують процесор. Тут GIL стає реальною проблемою, адже навіть якщо створити кілька потоків, вони не зможуть одночасно виконуватись на різних ядрах. Через це програма не отримує ніякого прискорення, а іноді навіть працює повільніше через витрати на перемикання контекстів між потоками. Саме тому в таких випадках багатопоточність у Python неефективна, і краще використовувати інший підхід – багатопроцесність.

Замість потоків можна створювати окремі процеси, кожен з яких буде незалежним і зможе використовувати повне навантаження на своєму ядрі. В Python для цього є бібліотека `multiprocessing`, яка дозволяє запускати кілька процесів і розподіляти між ними роботу. Наприклад, ось код, що демонструє використання пулу процесів для паралельних обчислень квадратів чисел:

```python
import multiprocessing

def square(n):
    return n * n

pool = multiprocessing.Pool(processes=4)
results = pool.map(square, range(10))
print(results)
```

Кожен процес у цьому випадку буде незалежним і працюватиме на окремому ядрі, що дозволить досягти справжнього паралелізму. Це показує, що для CPU-bound задач багатопроцесність значно ефективніша за багатопоточність, адже вона дозволяє повністю використовувати можливості багатоядерного процесора.

Таким чином, вибір між потоками та процесами залежить від типу задачі. Якщо програма активно взаємодіє з мережею, базою даних або файловою системою, багатопоточність буде хорошим рішенням. Якщо ж головне навантаження припадає на процесор, варто використовувати multiprocessing. Розуміння цієї різниці допомагає писати ефективнішу та продуктивнішу програму.

### **Синхронізація потоків**

Коли кілька потоків працюють одночасно та звертаються до спільних ресурсів, виникає проблема синхронізації. Якщо кілька потоків одночасно змінюють спільні дані, може відбутися ситуація, коли результат буде непередбачуваним. Це відоме як "гонка станів" (race condition), і воно може призвести до некоректної роботи програми або навіть до серйозних помилок.

Уявімо, що у нас є глобальна змінна-лічильник, яка збільшується різними потоками. Якщо не контролювати доступ до цієї змінної, можна отримати неправильні результати. Наприклад, два потоки можуть одночасно зчитати значення, обчислити його нове значення і записати його назад, не враховуючи зміни, які зробив інший потік. Це призведе до втрати деяких інкрементів.

Щоб уникнути подібних проблем, використовують механізми синхронізації. В Python є кілька основних способів синхронізації потоків: локи (Locks), м’ютекси (Mutexes) та семафори (Semaphores).

**Локи** – це найпростіший спосіб забезпечити взаємовиключний доступ до ресурсу. Коли один потік отримує лок, інші потоки не можуть отримати доступ до ресурсу, поки лок не буде звільнений. Це дозволяє гарантувати, що тільки один потік працює з ресурсом у певний момент часу. Приклад використання локів у Python виглядає так:

```python
import threading

lock = threading.Lock()
shared_resource = 0

def worker():
    global shared_resource
    with lock:
        temp = shared_resource
        temp += 1
        shared_resource = temp

threads = [threading.Thread(target=worker) for _ in range(10)]
for t in threads: t.start()
for t in threads: t.join()

print("Фінальне значення:", shared_resource)
```

Тут використовується `with lock:`, що є більш безпечним способом роботи з локами, оскільки гарантує автоматичне звільнення ресурсу після виходу з блоку коду.

**М’ютекси** працюють схоже на локи, але мають додатковий захист від повторного блокування самим потоком. Якщо потік уже заблокував м’ютекс, він не може заблокувати його повторно, поки не звільнить його. Це запобігає потенційним проблемам, коли один і той самий потік намагається отримати ресурс двічі, що може призвести до взаємного блокування (deadlock).

**Семафори** використовуються, коли потрібно обмежити кількість потоків, які можуть одночасно працювати з ресурсом. Наприклад, якщо у нас є база даних, яка підтримує одночасно лише два з’єднання, семафор допоможе обмежити кількість потоків, які можуть одночасно звертатися до бази. Ось як це виглядає в коді:

```python
import threading
import time
import random

semaphore = threading.Semaphore(2)

def worker(name):
    with semaphore:
        print(f"{name} отримав ресурс")
        time.sleep(random.randint(1, 3))
        print(f"{name} звільнив ресурс")

threads = [threading.Thread(target=worker, args=(f"Потік-{i}",)) for i in range(5)]
for t in threads: t.start()
for t in threads: t.join()
```

У цьому прикладі тільки два потоки одночасно можуть отримати доступ до ресурсу. Інші потоки змушені чекати, поки один із попередніх потоків звільнить семафор.

Синхронізація потоків – це важлива частина багатопотокового програмування, адже неправильне управління доступом до ресурсів може призвести до непередбачуваних помилок. Вибір між локами, м’ютексами та семафорами залежить від конкретного сценарію: локи підходять для простого блокування доступу, м’ютекси корисні для складніших ситуацій, коли потік може повторно блокувати ресурс, а семафори дозволяють контролювати кількість потоків, які можуть одночасно працювати з ресурсом.

### **Локи, рекурсивні локи, м’ютекси та семафори**

#### **Локи (Locks)**

Лок (`threading.Lock()`) є базовим механізмом синхронізації потоків у Python. Його головна задача – забезпечити взаємовиключний доступ до ресурсу. Коли один потік отримує лок, інші потоки змушені чекати, поки цей лок не буде звільнений. Це гарантує, що одночасно тільки один потік може працювати з критичною секцією коду, тим самим запобігаючи гонкам станів та некоректним змінам даних.

Локи в Python можуть використовуватись у двох основних варіантах: явне блокування та автоматичне керування через `with`.

При явному блокуванні потік викликає `lock.acquire()`, після чого інші потоки змушені чекати, поки поточний потік не виконає `lock.release()`.

```python
import threading

lock = threading.Lock()
shared_resource = 0

def worker():
    global shared_resource
    lock.acquire()  # Захоплюємо лок
    shared_resource += 1
    lock.release()  # Звільняємо лок

threads = [threading.Thread(target=worker) for _ in range(10)]
for t in threads: t.start()
for t in threads: t.join()

print("Фінальне значення:", shared_resource)
```

Однак такий підхід може бути небезпечним: якщо в коді між `acquire()` і `release()` виникне помилка або виняток, лок може ніколи не бути звільнений, і програма зависне.

Більш безпечним є використання `with lock:`. У цьому випадку навіть якщо всередині блоку виникне помилка, лок автоматично звільниться.

```python
import threading

lock = threading.Lock()
shared_resource = 0

def worker():
    global shared_resource
    with lock:  # Безпечне блокування
        shared_resource += 1

threads = [threading.Thread(target=worker) for _ in range(10)]
for t in threads: t.start()
for t in threads: t.join()

print("Фінальне значення:", shared_resource)
```

#### **Рекурсивні локи (RLock)**

Рекурсивний лок (`threading.RLock()`) відрізняється від звичайного локa тим, що його може повторно заблокувати той самий потік без виникнення deadlock'у.

Звичайний лок не дозволяє одному й тому ж потоку заблокувати себе вдруге, оскільки це призвело б до зависання. Уявімо, що потік вже виконав `lock.acquire()`, а потім викликає ту ж функцію, яка знову намагається захопити цей лок. Це спричиняє безкінечне очікування, оскільки потік сам блокує себе.

Рекурсивний лок вирішує цю проблему, дозволяючи одному й тому ж потоку отримати блокування кілька разів, поки воно не буде повністю звільнене. Це корисно в ситуаціях, коли функція з локом викликає іншу функцію, яка також використовує той самий лок.

```python
import threading

rlock = threading.RLock()

def recursive_function(n):
    if n <= 0:
        return
    with rlock:
        print(f"Виклик {n}")
        recursive_function(n - 1)

recursive_function(5)
```

Тут без `RLock` програма зависла б, оскільки кожен рекурсивний виклик знову намагався б отримати лок.

#### **М’ютекси (Mutex – Mutual Exclusion)**

М’ютекс – це концептуально той самий механізм, що і лок, але використовується в ширшому контексті. У Python м’ютекси реалізуються через `threading.Lock()`. Вони гарантують, що тільки один потік може отримати доступ до ресурсу в певний момент часу.

Основна різниця між м’ютексом і звичайним локом полягає у використанні між процесами. Якщо лок використовується тільки в межах одного процесу, то м’ютекси можуть використовуватися для міжпроцесного блокування (через `multiprocessing.Lock()`).

Ось приклад використання м’ютекса для спільного доступу до ресурсів у багатопотоковому середовищі:

```python
import threading
import time

mutex = threading.Lock()

def critical_section(name):
    with mutex:
        print(f"{name} отримав доступ до ресурсу")
        time.sleep(2)
        print(f"{name} звільнив ресурс")

threads = [threading.Thread(target=critical_section, args=(f"Потік-{i}",)) for i in range(3)]
for t in threads: t.start()
for t in threads: t.join()
```

Тут кожен потік отримує доступ до спільного ресурсу, але інші потоки змушені чекати, поки попередній потік звільнить блокування.

#### **Семафори (Semaphores)**

Семафор (`threading.Semaphore()`) – це узагальнення м’ютекса, яке дозволяє кільком потокам одночасно отримати доступ до ресурсу. На відміну від звичайного локa, який дозволяє лише одному потоку мати доступ до критичної секції, семафор дозволяє обмежену кількість одночасних доступів.

Наприклад, якщо у вас є база даних, яка підтримує максимум три одночасні підключення, можна використовувати семафор із значенням 3. Це означає, що одночасно три потоки можуть отримати доступ, а інші будуть чекати, поки місце звільниться.

```python
import threading
import time
import random

semaphore = threading.Semaphore(2)

def worker(name):
    with semaphore:
        print(f"{name} отримав ресурс")
        time.sleep(random.randint(1, 3))
        print(f"{name} звільнив ресурс")

threads = [threading.Thread(target=worker, args=(f"Потік-{i}",)) for i in range(5)]
for t in threads: t.start()
for t in threads: t.join()
```

У цьому коді одночасно можуть працювати лише два потоки, навіть якщо ми створили п’ять потоків. Третій, четвертий і п’ятий потоки змушені чекати, поки хтось із перших двох звільнить семафор.

Окрім звичайного семафора, є також **лічильниковий семафор (`threading.BoundedSemaphore()`)**, який працює аналогічно, але з додатковим захистом. Якщо один із потоків випадково викличе `release()` більше разів, ніж було `acquire()`, звичайний семафор дозволить це зробити, а `BoundedSemaphore` викличе помилку. Це допомагає запобігати помилкам у логіці програми.

### **Чому GIL не робить механізми синхронізації зайвими?**

#### **1. GIL не гарантує послідовний доступ до змінних у багатопотоковому коді**

Хоча GIL запобігає одночасному виконанню двох потоків на рівні інтерпретатора Python, він не гарантує атомарність операцій у багатопотоковому середовищі. Наприклад, операції над змінними, які здаються "простими", насправді можуть виконуватися в кілька етапів.

Розглянемо приклад:

```python
import threading

counter = 0

def increment():
    global counter
    for _ in range(100000):
        counter += 1

threads = [threading.Thread(target=increment) for _ in range(2)]
for t in threads: t.start()
for t in threads: t.join()

print(counter)  # Очікуємо 200000, але результат може бути меншим
```

Операція `counter += 1` насправді виконується у три етапи:

1. Зчитування поточного значення `counter`
2. Додавання 1
3. Запис оновленого значення назад

Якщо між цими етапами GIL переключить контекст і інший потік виконає ту ж операцію, результати можуть бути некоректними. Через це навіть у Python необхідно використовувати **локи** для захисту критичних секцій.

```python
import threading

counter = 0
lock = threading.Lock()

def increment():
    global counter
    for _ in range(100000):
        with lock:
            counter += 1

threads = [threading.Thread(target=increment) for _ in range(2)]
for t in threads: t.start()
for t in threads: t.join()

print(counter)  # Завжди 200000
```

Тут `lock` гарантує, що операція `counter += 1` виконується атомарно, не допускаючи зміни змінної одночасно двома потоками.

---

#### **2. GIL працює лише в CPython, але не у всіх реалізаціях Python**

GIL є особливістю CPython (стандартної імплементації Python), але інші версії Python, такі як Jython (на Java) та IronPython (на .NET), не мають GIL. Якщо писати код із припущенням, що GIL "захистить" від проблем паралелізму, цей код може виявитися некоректним у середовищах без GIL.

Якщо в майбутньому Python без GIL (PEP 703) стане стандартом, програми, які раніше покладалися на GIL, можуть почати працювати некоректно. Використання явних механізмів синхронізації зробить код стійкішим до таких змін.

---

#### **3. GIL не впливає на зовнішні ресурси (взаємодія з файлами, мережею, базами даних)**

Навіть у середовищі з GIL багатопотокові програми можуть одночасно працювати з ресурсами, які не контролюються GIL. Наприклад, якщо два потоки пишуть у файл або взаємодіють з базою даних, GIL не регулює їхню роботу.

Уявімо ситуацію, коли два потоки записують лог-файли:

```python
import threading

def write_log():
    with open("log.txt", "a") as f:
        for _ in range(100):
            f.write("Логування з потоку\n")

threads = [threading.Thread(target=write_log) for _ in range(5)]
for t in threads: t.start()
for t in threads: t.join()
```

Цей код може спричинити хаос у файлі, оскільки потоки можуть записувати рядки одночасно, що призведе до пошкоджених або злитих записів.

Використовуючи лок, можна гарантувати, що кожен потік записуватиме у файл без перетинання з іншими:

```python
import threading

lock = threading.Lock()

def write_log():
    with lock:
        with open("log.txt", "a") as f:
            for _ in range(100):
                f.write("Логування з потоку\n")

threads = [threading.Thread(target=write_log) for _ in range(5)]
for t in threads: t.start()
for t in threads: t.join()
```

Завдяки `lock`, тільки один потік одночасно виконує запис у файл, що запобігає конфліктам.

---
### **Механізм роботи GIL у CPython**

GIL (Global Interpreter Lock) — це глобальне блокування інтерпретатора Python, яке регулює виконання потоків у CPython. Його головна функція — гарантувати, що в будь-який момент часу лише один потік виконує байткод Python, навіть якщо в системі є кілька ядер процесора.

Щоб зрозуміти, як саме працює GIL, розглянемо його основні компоненти та механізми, які визначають порядок виконання потоків у CPython.

---

### **1. Основні компоненти GIL**

GIL працює за допомогою таких основних елементів:

- **Глобальна змінна `gil`**  
    У CPython GIL представлений як глобальна змінна у вихідному коді інтерпретатора. Це змінна, яка вказує, чи дозволено поточному потоку виконувати байткод Python.
    
- **Механізм блокування (Lock)**  
    GIL реалізований як **м’ютекс (mutex)** — взаємовиключний механізм, який дозволяє одному потоку виконувати код, а інші змушує чекати.
    
- **Таймер перемикання потоків**  
    Python використовує механізм **контекстного перемикання** між потоками. Через певний проміжок часу один потік звільняє GIL, щоб інші потоки могли отримати можливість виконання.
    
- **Сигнали `Py_BEGIN_ALLOW_THREADS` і `Py_END_ALLOW_THREADS`**  
    У коді CPython є спеціальні макроси, які дозволяють тимчасово звільняти GIL для виконання операцій, що не залежать від Python (наприклад, очікування введення-виведення).
    

---

### **2. Процес роботи GIL у багатопотоковій програмі**

GIL працює циклічно:

1. **Один потік отримує GIL**  
    Коли потік запускається, він повинен отримати GIL. Якщо GIL зайнятий іншим потоком, потік змушений чекати, поки той його звільнить.
    
2. **Потік виконує певну кількість інструкцій**  
    Потік виконує байткод Python, поки не виконає певну кількість інструкцій (це називається **GIL quantum**, за замовчуванням близько 5 мілісекунд).
    
3. **GIL тимчасово звільняється**  
    Після закінчення квантового часу потік тимчасово звільняє GIL, щоб інші потоки могли отримати можливість виконання. Якщо жоден інший потік не чекає, той самий потік може знову отримати GIL.
    
4. **Якщо потік очікує I/O, він звільняє GIL**  
    Якщо потік виконує операцію введення-виведення (наприклад, читає файл або очікує відповідь від сервера), він викликає `Py_BEGIN_ALLOW_THREADS`, щоб тимчасово звільнити GIL. Інші потоки можуть у цей час виконуватися.
    
5. **Інший потік отримує GIL**  
    Якщо є інші потоки, вони можуть отримати GIL після перемикання контексту. Якщо ні, потік, який виконувався раніше, просто продовжить роботу.
    

Процес повторюється циклічно, що створює ефект псевдопаралельного виконання потоків.

---

### **3. Як виглядає GIL у вихідному коді CPython?**

Якщо заглянути у вихідний код CPython (файл `ceval.c`), можна побачити механізм GIL. Основний механізм контролю потоків виглядає так:

```c
/* Отримання GIL */
PyEval_AcquireLock();

/* Виконання байткоду */
while (opcodes_left > 0) {
    execute_next_opcode();
    opcodes_left--;
}

/* Звільнення GIL */
PyEval_ReleaseLock();
```

Коли потік отримує GIL (`PyEval_AcquireLock()`), він починає виконувати інструкції Python. Після досягнення певної кількості інструкцій або після запиту на введення-виведення (`PyEval_ReleaseLock()`), GIL звільняється і може бути отриманий іншим потоком.

У CPython є механізм **thread switching**, який виконує перевірку, чи потрібно перемикати потік, кожні 5 мілісекунд:

```c
if (--gil_interval <= 0) {
    gil_interval = DEFAULT_INTERVAL;
    PyThreadState_Swap(next_thread);
}
```

Тут `gil_interval` визначає, як довго потік може утримувати GIL, перш ніж відбудеться примусове перемикання контексту.

---

### **4. Взаємодія GIL з введенням-виведенням (I/O-bound задачі)**

GIL блокує багатопотоковість для обчислювальних задач, але не для операцій введення-виведення. Коли потік виконує операцію, яка не потребує обчислень (наприклад, очікує відповіді від мережі), Python дозволяє іншим потокам отримати GIL.

Це реалізується за допомогою наступних макросів у вихідному коді CPython:

```c
Py_BEGIN_ALLOW_THREADS;
/* Операція, яка не використовує Python */
do_something_that_takes_time();
Py_END_ALLOW_THREADS;
```

Коли Python зустрічає `Py_BEGIN_ALLOW_THREADS`, він тимчасово звільняє GIL, дозволяючи іншим потокам виконуватись. Коли I/O-операція завершується, потік повторно отримує GIL (`Py_END_ALLOW_THREADS`) і продовжує виконання.

### **Практичні приклади багатопотоковості в Python**

Тепер, коли механізм роботи GIL зрозумілий, розглянемо кілька практичних прикладів, які демонструють, як працює багатопотоковість у Python. Ми розглянемо:

1. **Просту програму з потоками**
2. **Вплив GIL на CPU-bound задачі**
3. **Правильне використання локів**
4. **Приклад роботи з семафорами**
5. **Оптимальне рішення для CPU-bound задач за допомогою multiprocessing**

---

### **1. Запуск потоків у Python**

Розглянемо найпростіший приклад багатопотоковості, де створюється кілька потоків, які виконують однакову функцію.

```python
import threading
import time

def worker(n):
    print(f"Потік {n} почав роботу")
    time.sleep(2)
    print(f"Потік {n} завершив роботу")

threads = [threading.Thread(target=worker, args=(i,)) for i in range(5)]

for t in threads:
    t.start()

for t in threads:
    t.join()

print("Всі потоки завершили роботу")
```

Тут створюються п’ять потоків, кожен з яких виконується незалежно і завершує свою роботу через 2 секунди. Однак через GIL ці потоки не виконуються одночасно в справжньому паралельному режимі, а лише чергуються.

---

### **2. Вплив GIL на CPU-bound задачі**

Давайте подивимося, як GIL обмежує продуктивність у випадку інтенсивних обчислень. Наприклад, обчислимо суму чисел від 1 до 50_000_000 у кількох потоках.

```python
import threading
import time

COUNT = 50_000_000

def countdown(n):
    while n > 0:
        n -= 1

t1 = threading.Thread(target=countdown, args=(COUNT//2,))
t2 = threading.Thread(target=countdown, args=(COUNT//2,))

start = time.time()
t1.start()
t2.start()
t1.join()
t2.join()
end = time.time()

print(f"Час виконання: {end - start:.2f} секунд")
```

Очікувано, що два потоки мали б поділити роботу і виконати її вдвічі швидше, однак через GIL вони не можуть виконуватися паралельно, тому час виконання майже не зміниться порівняно з виконанням у одному потоці.

---

### **3. Використання локів для запобігання race condition**

Уявімо ситуацію, коли кілька потоків одночасно модифікують глобальну змінну, наприклад, лічильник.

```python
import threading

counter = 0

def increment():
    global counter
    for _ in range(100000):
        counter += 1  # Операція не атомарна!

threads = [threading.Thread(target=increment) for _ in range(5)]

for t in threads:
    t.start()
for t in threads:
    t.join()

print(f"Очікуваний результат: {5 * 100000}, реальний: {counter}")
```

Через те, що `counter += 1` — це не атомарна операція (складається із зчитування, збільшення та запису значення), можливі втрати інкрементів через race condition.

Правильний варіант із використанням `Lock`:

```python
import threading

counter = 0
lock = threading.Lock()

def increment():
    global counter
    for _ in range(100000):
        with lock:
            counter += 1  # Операція тепер захищена локом

threads = [threading.Thread(target=increment) for _ in range(5)]

for t in threads:
    t.start()
for t in threads:
    t.join()

print(f"Очікуваний результат: {5 * 100000}, реальний: {counter}")
```

Тепер результат буде коректним, оскільки тільки один потік може змінювати `counter` у певний момент часу.

---

### **4. Використання семафорів для обмеження доступу**

Семафори дозволяють обмежити кількість потоків, які одночасно отримують доступ до ресурсу. Наприклад, якщо ми хочемо, щоб одночасно працювали не більше двох потоків:

```python
import threading
import time

semaphore = threading.Semaphore(2)

def worker(n):
    with semaphore:
        print(f"Потік {n} отримав доступ до ресурсу")
        time.sleep(2)
        print(f"Потік {n} звільнив ресурс")

threads = [threading.Thread(target=worker, args=(i,)) for i in range(5)]

for t in threads:
    t.start()
for t in threads:
    t.join()
```

Тут одночасно виконуватимуться тільки два потоки, решта будуть чекати, поки один із перших двох не звільнить семафор.

---

### **5. Використання multiprocessing для CPU-bound задач**

Оскільки GIL не дозволяє багатопотоковість для обчислювальних задач, можна замість `threading` використовувати `multiprocessing`, де кожен процес буде виконуватися окремо і використовувати своє ядро процесора.

Той самий приклад підрахунку чисел, але з `multiprocessing`:

```python
import multiprocessing
import time

COUNT = 50_000_000

def countdown(n):
    while n > 0:
        n -= 1

p1 = multiprocessing.Process(target=countdown, args=(COUNT//2,))
p2 = multiprocessing.Process(target=countdown, args=(COUNT//2,))

start = time.time()
p1.start()
p2.start()
p1.join()
p2.join()
end = time.time()

print(f"Час виконання: {end - start:.2f} секунд")
```

На багатоядерному процесорі цей код працюватиме майже вдвічі швидше, оскільки `multiprocessing` обходить GIL, створюючи окремі процеси.

---

